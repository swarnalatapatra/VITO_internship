{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-03 22:10:47.531001\n",
      "\u001b[1m\u001b[37mthunder\u001b[m  Fri Jan  3 22:10:48 2020\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 58'C\u001b[m, \u001b[1m\u001b[32m 57 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m10936\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mdavid\u001b[m(\u001b[33m10926M\u001b[m)\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 54'C\u001b[m, \u001b[1m\u001b[32m 68 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m10936\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mdavid\u001b[m(\u001b[33m10926M\u001b[m)\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m11178\u001b[m MB |\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 63'C\u001b[m, \u001b[32m  1 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m10936\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mdavid\u001b[m(\u001b[33m10926M\u001b[m)\n",
      "\u001b[36m[4]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 53'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m10936\u001b[m / \u001b[33m11178\u001b[m MB | \u001b[1m\u001b[30mdavid\u001b[m(\u001b[33m10926M\u001b[m)\n",
      "\u001b[36m[5]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[31m 28'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m11178\u001b[m MB |\n",
      "\u001b[36m[6]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[31m 31'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m11178\u001b[m MB |\n",
      "\u001b[36m[7]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m11178\u001b[m MB |\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Dataset consist of 85730 patients data with 6251 features for each patient\n",
      "Function definitions executed\n",
      "Definitions DONE !!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ./Definitions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan  3 19:59:17 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 46%   62C    P2   109W / 250W |  10936MiB / 11178MiB |     79%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 40%   55C    P2    74W / 250W |  10936MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:07:00.0 Off |                  N/A |\n",
      "| 29%   29C    P8     7W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 51%   67C    P2   263W / 250W |  10936MiB / 11178MiB |     23%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  Off  | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 41%   56C    P2    83W / 250W |  10936MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  Off  | 00000000:0D:00.0 Off |                  N/A |\n",
      "| 29%   28C    P8     9W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  Off  | 00000000:0E:00.0 Off |                  N/A |\n",
      "| 29%   31C    P8     8W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  Off  | 00000000:0F:00.0 Off |                  N/A |\n",
      "| 29%   29C    P8     8W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     45002      C   python3                                    10926MiB |\n",
      "|    1     40140      C   python3                                    10926MiB |\n",
      "|    3     47310      C   python3                                    10926MiB |\n",
      "|    4     41549      C   python3                                    10926MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # so the IDs match nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"   # choose here your GPU (0-7)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import keras\n",
    "# from keras import backend as K\n",
    "import tensorflow.python.keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading numerical and categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51438, 321), (17146, 321))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD\n",
    "meta_train = pd.read_pickle(tts_path + '40_features_union_train_df_FINAL.pkl')\n",
    "meta_val = pd.read_pickle(tts_path + '40_features_union_val_df_FINAL.pkl')\n",
    "meta_train.shape, meta_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51438, 1), (17146, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD\n",
    "y_train = pd.read_pickle(tts_path + 'yu_train.pkl')\n",
    "y_val = pd.read_pickle(tts_path + 'yu_val.pkl')\n",
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Fundus Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZATION\n",
    "\n",
    "img_size = 250\n",
    "red_size = 224\n",
    "\n",
    "srcpath = '/ds2/data/retina/UK_BB/UK_BB_DATA/fundus/'\n",
    "funduspath_CR = DATA_dir + 'Fundus_images_250_CR/'\n",
    "trainpath = funduspath_CR + 'train/'\n",
    "valpath = funduspath_CR + 'val/'\n",
    "testpath = funduspath_CR + 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUGMENTATION\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Affine(scale=1.1),\n",
    "    iaa.Affine(rotate=(-10, 10)),\n",
    "    # iaa.GammaContrast(0.9),\n",
    "    iaa.Resize({\"height\": 230, \"width\": 230}),\n",
    "    iaa.CropToFixedSize(width=red_size, height=red_size)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = pd.read_pickle(funduspath_CR + 'valid_traindf_names.pkl')\n",
    "img_val = pd.read_pickle(funduspath_CR + 'valid_valdf_names.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((101834, 5), (33943, 5))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train.shape, img_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train['GTu'] = img_train['GTu'].astype(int)\n",
    "img_val['GTu'] = img_val['GTu'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ways to combine both inputs\n",
    "https://stats.stackexchange.com/questions/410745/combining-random-forests-and-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(dim):\n",
    "    # define our MLP network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=dim, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "\n",
    "    # return our model\n",
    "    return model\n",
    "\n",
    "def create_cnn():       \n",
    "    mobile_conv = MobileNet(weights='imagenet', include_top=False, input_shape=(red_size, red_size, 3))\n",
    "\n",
    "    # UnFreeze last conv layer\n",
    "    for layer in mobile_conv.layers[:78]:\n",
    "        layer.trainable = False\n",
    "    for layer in mobile_conv.layers[78:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    # Create the model\n",
    "    model = models.Sequential()\n",
    "    model.add(mobile_conv)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(4, activation='relu'))\n",
    " \n",
    "    return model\n",
    "\n",
    "learning_rate  = 0.0001 \n",
    "decay = 1e-5\n",
    "opt = Adam(lr=learning_rate, decay = decay) \n",
    "BATCH_SIZE = 32\n",
    "METRICS = [keras.metrics.BinaryAccuracy(name='Accuracy'),\n",
    "           Precision, \n",
    "           Recall, \n",
    "           F1,\n",
    "           keras.metrics.AUC(name='AUC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the MLP and CNN models\n",
    "mlp = create_mlp(meta_train.shape[1]) # categorical data\n",
    "cnn = create_cnn() # left eye input\n",
    "\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics=METRICS, optimizer=opt)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-67ac79bece99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               validation_steps=10)\n\u001b[0m",
      "\u001b[0;32m/ds/environments/python2020/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ds/environments/python2020/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ds/environments/python2020/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "n_epochs = 2\n",
    "print(\"[INFO] training model...\")\n",
    "hist = model.fit_generator(train_generator, \n",
    "                              epochs=n_epochs, \n",
    "                              steps_per_epoch=5,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    img = imageio.imread(path)\n",
    "    return(img)\n",
    "\n",
    "def preprocess_input(image):\n",
    "    rescale= 1./127.5\n",
    "    image = image * rescale\n",
    "    image = image - 1\n",
    "    images = [image, image, image, image]\n",
    "    images_aug = seq.augment_images(images)\n",
    "    return(images_aug[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = custom_generator(meta_train, y_train, img_train, trainpath, batch_size = 32, aug=True)\n",
    "validation_generator = custom_generator(meta_val, y_val, img_val, valpath, batch_size = 32, aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_generator(X1,Y1,X2,df_path,batch_size = 32,aug=True):\n",
    "    \n",
    "    indices = np.arange(len(X1))\n",
    "    \n",
    "    while True:\n",
    "        samples = img_train.sample(batch_size)\n",
    "        imgs = samples[samples.columns[0]]\n",
    "        labels = samples[samples.columns[4]]\n",
    "        f_indices = np.random.choice(indices,  size = batch_size)\n",
    "        \n",
    "        img_input = []\n",
    "        meta_input = []\n",
    "        meta_label = []\n",
    "          \n",
    "        # Read in each input, and perform preprocessing\n",
    "        \n",
    "        for i in imgs:\n",
    "            inp = get_img(df_path+i)\n",
    "            if (aug == True):\n",
    "                inp = preprocess_input(image=inp)\n",
    "            img_input.append(inp)\n",
    "                \n",
    "        for i in f_indices:\n",
    "            feat = X1.iloc[i].tolist()\n",
    "            f_label = Y1.iloc[i]\n",
    "            \n",
    "            meta_input.append(feat)\n",
    "            meta_label.append(f_label)\n",
    "            \n",
    "        batch_img = np.array( img_input )\n",
    "        img_label = np.array( labels )\n",
    "        \n",
    "        batch_feature = np.array( meta_input )\n",
    "        feat_label = np.array( meta_label )\n",
    "\n",
    "        yield( batch_img,img_label, batch_feature,feat_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object custom_generator at 0x7fd197713a50>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_generator(meta_train, y_train, img_train, trainpath, batch_size = 32, aug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# create the input to our final set of layers as the *output* of both\n",
    "# the MLP and CNN\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    " \n",
    "# our final FC layer head will have two dense layers, the final one\n",
    "# being our regression head\n",
    "x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    " \n",
    "# our final model will accept categorical/numerical data on the MLP\n",
    "# input and images on the CNN input, outputting a single value (the\n",
    "# predicted price of the house)\n",
    "model = Model(inputs=[mlp.input, cnn.input], outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(dim, regress=False):\n",
    "    # define our MLP network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "    # return our model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n",
    "    # initialize the input shape and channel dimension\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    # define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    "\n",
    "    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "        # if this is the first CONV layer then set the input\n",
    "        # appropriately\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "\n",
    "        # CONV => RELU => BN => POOL\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(4)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    # construct the CNN\n",
    "    model = Model(inputs, x)\n",
    "\n",
    "    # return the CNN\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split image data as per above train_x and val_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75699, 15) (8411, 15) (75699,) (8411,)\n"
     ]
    }
   ],
   "source": [
    "## OLD\n",
    "# train_x, val_x, train_y, val_y = train_test_split(df, y, test_size = 0.1, random_state = 13, stratify=y)\n",
    "# print(train_x.shape, val_x.shape, train_y.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of the data for training and the remaining 25% for testing\n",
    "print(\"[INFO] processing data...\")\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = train_test_split(data_df, images, test_size=0.25, random_state=42)\n",
    " \n",
    "# find the largest house price in the training set and use it to\n",
    "# scale our house prices to the range [0, 1] (will lead to better\n",
    "# training and convergence)\n",
    "maxPrice = trainAttrX[\"price\"].max()\n",
    "trainY = trainAttrX[\"price\"] / maxPrice\n",
    "testY = testAttrX[\"price\"] / maxPrice\n",
    " \n",
    "# process the house attributes data by performing min-max scaling\n",
    "# on continuous features, one-hot encoding on categorical features,\n",
    "# and then finally concatenating them together\n",
    "(trainAttrX, testAttrX) = datasets.process_house_attributes(df,\n",
    "\ttrainAttrX, testAttrX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2020",
   "language": "python",
   "name": "python2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
